# ECE271a-Statistical-Learning-I
HW1:
This is the first in a series of computer problems where we will get a feel for the difficulty of practical pattern recognition problems, such as computer vision. 
The goal is to segment the “cheetah” image (shown below in the left) into its two components, cheetah (foreground) and grass (background).

To formulate this as a pattern recognition problem, we need to decide on an observation space. Here we will be using the space of 8 × 8 image blocks, i.e. we view each image as a collection of 8 × 8 blocks. For each block we compute the discrete cosine transform (function dct2 on MATLAB) and obtain an array of 8 × 8 frequency coefficients. We do this because the cheetah and the grass have different textures, with different frequency decompositions and the two classes should be better separated in the frequency domain. We then convert each 8 × 8 array into a 64 dimensional vector because it is easier to work with vectors than with arrays. The file Zig-Zag Pattern.txt contains the position (in the 1D vector) of each coefficient in the 8 × 8 array. The file TrainingSamplesDCT 8.mat contains a training set of vectors obtained from a similar image (stored as a matrix, each row is a training vector) for each of the classes. There are two matrices, TrainsampleDCT BG and TrainsampleDCT FG for foreground and background samples respectively.
To make the task of estimating the class conditional densities easier, we are going to reduce each vector to a scalar. For this, for each vector, we compute the index (position within the vector) of the coefficient that has the 2nd largest energy value (absolute value). This is our observation or feature X. (The reason we do not use the coefficient with the largest energy is that it is always the so-called “DC” coefficient, which contains the mean of the block). By building an histogram of these indexes we obtain the class-conditionals for the two classes PX|Y (x|cheetah) and PX|Y (x|grass). The priors PY (cheetah) and PY (grass) should also be estimated from the training set.

a) using the training data in TrainingSamplesDCT 8.mat, what are reasonable estimates for the prior probabilities?
b) using the training data in TrainingSamplesDCT 8.mat, compute and plot the index histograms PX|Y (x|cheetah) and PX|Y (x|grass).
c) for each block in the image cheetah.bmp, compute the feature X (index of the DCT coefficient with 2nd greatest energy). Compute the state variable Y using the minimum probability of error rule based on the probabilities obtained in a) and b). Store the state in an array A. Using the commands imagesc and colormap(gray(255)) create a picture of that array.
d) The array A contains a mask that indicates which blocks contain grass and which contain the cheetah. Compare it with the ground truth provided in image cheetah mask.bmp (shown below on the right) and compute the probability of error of your algorithm.

HW2: Once again we use the decomposition into 8 × 8 image blocks, compute the DCT of each block, and zig-zag scan. However, we are going to assume that the class-conditional densities are multivariate Gaussians of 64 dimensions.
Note: The training examples we used last time contained the absolute value of the DCT coefficients instead of the coefficients themselves. Please download the file TrainingSamplesDCT 8 new.mat and use it in this and all future exercises. For simplicity, I will still refer to it as TrainingSamplesDCT 8.mat.

a) Using the training data in TrainingSamplesDCT 8.mat compute the histogram estimate of the prior PY (i), i ∈ {cheetah, grass}. Using the results of problem 2 compute the maximum likelihood estimate for the prior probabilities. Compare the result with the estimates that you obtained last week. If they are the same, interpret what you did last week. If they are different, explain the differences.

b) Using the training data in TrainingSamplesDCT 8.mat, compute the maximum likelihood estimates for the parameters of the class conditional densities PX|Y (x|cheetah) and PX|Y (x|grass) under the Gaussian assumption. Denoting by X = {X1, . . . , X64} the vector of DCT coefficients, create 64 plots with the marginal densities for the two classes - PXk |Y (xk |cheetah) and PXk |Y (xk |grass), k = 1, . . . , 64 - on each. Use different line styles for each marginal. Select, by visual inspection, what you think are the best 8 features for classification purposes and what you think are the worst 8 features (you can use the subplot command to compare several plots at a time). Hand in the plots of the marginal densities for the best-8 and worst-8 features (once again you can use subplot, this should not require more than two sheets of paper). In each subplot indicate the feature that it refers to.

c) Compute the Bayesian decision rule and classify the locations of the cheetah image using i) the 64-dimensional Gaussians, and ii) the 8-dimensional Gaussians associated with the best 8 features. For the two cases, plot the classification masks and compute the probability of error by comparing with cheetah mask.bmp. Can you explain the results?
